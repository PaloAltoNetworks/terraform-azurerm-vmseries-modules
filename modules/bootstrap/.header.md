# Palo Alto Networks Bootstrap Module for Azure

A terraform module for deploying a storage account and the dependencies required to
[bootstrap a VM-Series firewalls in Azure](https://docs.paloaltonetworks.com/vm-series/9-1/vm-series-deployment/bootstrap-the-vm-series-firewall/bootstrap-the-vm-series-firewall-in-azure.html#idd51f75b8-e579-44d6-a809-2fafcfe4b3b6).

It can create (or source an existing) Azure Storage Account and it can create (or source) multiple File Shares withing the Storage
Account and upload files to them. When creating File Shares each share will contain a folder structure required by the bootstrap
package. When sourcing existing shares, you can disable the folder structure creation, but keep in mind that the folders have to
present on the share before you try to upload any files to them.

The file uploading can be done in two ways:

1. either by specifying single files or
2. by providing a path to a local bootstrap package.

Keep in mind that if you provide both, the former takes precedence by the latter, meaning that when uploaded, each single file
specification will override files from the local bootstrap package.

## Usage

For more *real life* code please check [examples folder](../../examples/).
The examples below are just showing 3 typical use cases.

### Empty Storage account

The module is used only to create a Storage Account with module defaults where possible.

```hcl
module "empty_storage" {
  source = "../../modules/bootstrap"

  name                = "someemptystorage"
  resource_group_name = "rg-name"
  location            = "North Europe"
}
```

### Full bootstrap storage

This code will create a storage account for 3 NGFWs. Please **note** that:

- we will override the default access tier from `Cool` to `Hot` and increase the default quota to 20GB
- we will lower the default TLS to 1.1 and limit access to the Storage Account to one public IP
- `vm01` and `vm02` will use a full bootstrap package stored locally under the `bootstrap_package` path
- for `vm01` we will additionally overwrite some files from the bootstrap package
- `vm03` will not use a full bootstrap package, we will upload just a single file to the Storage Account. Additionally we will
    override the `access_tier` for this File Share to `Cool` and the quota to 1GB.

```hcl
module "bootstrap" {
  source = "../../modules/bootstrap"

  name                = "samplebootstrapstorage"
  resource_group_name = "rg-name"
  location            = "North Europe"

  file_shares_configuration = {
    access_tier = "Hot"
    quota       = 20
  }
  storage_network_security = {
    min_tls_version    = "TLS1_1"
    allowed_public_ips = ["1.2.3.4"]
  }
  file_shares = {
    "vm01" = {
      name                   = "vm01"
      bootstrap_package_path = "bootstrap_package"
      bootstrap_files = {
        "files/init-cfg.txt"         = "config/init-cfg.txt"
        "files/nested/bootstrap.xml" = "config/bootstrap.xml"
      }
    }
    "vm02" = {
      name                   = "vm02"
      bootstrap_package_path = "./bootstrap_package/"
    }
    "vm03" = {
      name        = "vm03"
      access_tier = "Cool"
      quota       = 1
      bootstrap_files = {
        "files/init-cfg.txt" = "config/init-cfg.txt"
      }
    }
  }
}
```

### Source existing Storage Account and File Share

The sample below shows how to source an existing Storage Account with an existing File Share.

Please **note** that we will also skip bootstrap package folder structure creation. The sourced File Share should have this folder
structure already present.

```hcl
module "existing_storage" {
  source = "../../modules/bootstrap"

  storage_account = {
    create = false
  }  
  name                   = "sampleexistingstorage"
  resource_group_name    = "rg-name"

  file_shares_configuration = {
    create_file_shares            = false
    disable_package_dirs_creation = true
  }
  file_shares = {
    existing_share = {
      name                   = "bootstrap"
      bootstrap_package_path = "bootstrap_package"
    }
  }
}
```

## MD5 file hashes

This module uses MD5 hashes to verify file content change. This means that any file modification done between Terraform runs will
be discovered and the remote file will be overwritten. This has some implications though.

The module can calculate hashes for the existing files - any files that were present before Terraform run.

If however you are creating some files on the fly (templating for instance) you have to provide the MD5 hashes yourself. For more
details refer to the [var.file_shares](#file_shares) variable documentation.
